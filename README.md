# AlitaOS ‚Äî Your AI Live Assistant

![Meet Alita](app/static/alita.png)

AlitaOS is a streamlined, voice‚Äëfirst AI assistant built with Streamlit and the OpenAI API. It uses Realtime WebRTC for sub‚Äësecond, bi‚Äëdirectional audio. Speak naturally and Alita speaks back. A live transcript and animated avatar complete the hands‚Äëfree experience.

## Highlights

- Realtime voice in/out via OpenAI Realtime (WebRTC) ‚Äî minimal latency, no polling
- Live transcript panel for both your speech and Alita‚Äôs responses
- Animated avatar that ‚Äúspeaks‚Äù when audio plays
- Image generation via OpenAI Images (gpt-image-1) with style/size support
- Web search tool with Tavily (API key) and DuckDuckGo fallback (no key)
- Save to file: Export assistant replies and web results to PDF, MD, DOCX, CSV, XLSX, PPTX, TXT, JSON, PY
- Provider selector (Auto/Tavily/DuckDuckGo) and Top‚ÄëN saving for search results
- Simple, clean Streamlit UI; HTTPS launchers for consistent mic support

## Requirements

- Python 3.10+
- OpenAI API key in a `.env` at project root:

  ```env
  OPENAI_API_KEY=sk-...
  # Optional: If set, Tavily will be used for richer results; otherwise DuckDuckGo fallback is used
  TAVILY_API_KEY=tvly-...
  ```

- macOS/Linux: OpenSSL (usually preinstalled); Windows: OpenSSL on PATH for HTTPS launcher

## Install

1) Create venv and install deps automatically via the launchers. Or manually:

   ```bash
   python3 -m venv alitaOS
   source alitaOS/bin/activate
   pip install -r requirements.txt
   ```

## Launch (HTTP, fast local dev)

```bash
./launch_streamlit.sh
```

Open <http://localhost:8501> and choose ‚Äúüéß Live Assistant‚Äù. Click Start and grant mic permissions.

## Launch (HTTPS, recommended for mic reliability)

```bash
./launch_streamlit_https.sh
```

This auto‚Äëgenerates a self‚Äësigned cert and serves Streamlit at <https://localhost:8501>. Accept the browser warning once. The realtime proxy also runs with TLS at <https://localhost:8787>.

### Windows Launchers

- HTTP: `launch_streamlit.bat` (starts Streamlit + realtime proxy)
- HTTPS: `launch_streamlit_https.bat` (generates certs, starts Streamlit HTTPS + realtime proxy TLS)

## Environment Variables

- `OPENAI_API_KEY` ‚Äî required
- `OPENAI_REALTIME_MODEL` ‚Äî default: `gpt-4o-realtime-preview-2024-12-17`
- `ALITA_REALTIME_PORT` ‚Äî default: `8787`
- `TAVILY_API_KEY` ‚Äî optional; enables Tavily provider for `search.web`

## Project Structure

```text
app/
  alita_streamlit.py      # Streamlit UI
  realtime_proxy.py       # FastAPI SDP proxy for OpenAI Realtime
  static/
    alita.png            # (optional) avatar image used in UI
tools/                    # image, search, stock, chart, python_file
utils/                    # ai_models.py (OpenAI only)
scratchpad/saved          # default folder for exported files
```

## Avatar (Speaking Animation)

- Place your avatar image at `app/static/alita.png` (PNG or JPEG). The UI animates a glow around the avatar when Alita is speaking, driven by a WebAudio analyser on the incoming audio stream.
- If the file is missing, a placeholder is shown.

## Live Transcript

The ‚Äúüéß Live Assistant‚Äù panel shows a rolling transcript. It parses Realtime events over a data channel; content may vary by model version. We‚Äôll keep iterating to improve robustness as OpenAI‚Äôs event schema evolves.

## Saving Files (New)

You can now save content generated by the assistant or returned by web search:

- Save reply: A toolbar below the Live Assistant lets you save the latest assistant message.
  - Choose format (MD, PDF, DOCX, TXT, JSON, PPTX) and filename (date‚Äëstamped by default).
  - Click ‚ÄúSave reply‚Äù to export via the `file.save` tool.
- Save search results: Each search result card includes controls to export the list or a short summary.
  - Pick format and a Top‚ÄëN value (1‚Äì10) to limit results; defaults to 3.
  - ‚ÄúSave results‚Äù exports a formatted list with links/snippets (CSV/XLSX/JSON use structured rows).
  - ‚ÄúSave summary‚Äù exports a concise, local summary of Top‚ÄëN results.

All files are written under `scratchpad/saved` for safety. Filenames default to include a timestamp (e.g., `assistant-reply-YYYYMMDD-HHMM.md`).

Supported formats: `pdf, md, docx, csv, xlsx, pptx, txt, json, py`.

Notes:
- For CSV/XLSX/JSON, provide rows of objects; the UI does this for search results.
- For text formats (md/txt/docx/pdf/pptx/py), the `content` string is used.
- If you supply a mismatched extension, the system corrects it to match the selected format.

### Provider Selection

The Live Assistant includes a provider selector (Auto/Tavily/DuckDuckGo). If `TAVILY_API_KEY` is present, the default is Tavily; otherwise DuckDuckGo is used. The chosen provider is sent with each `search.web` call.

## Troubleshooting

- No mic prompt or errors about getUserMedia: use the HTTPS launcher and ensure you granted microphone permissions to <https://localhost:8501>.
- Proxy errors (SDP exchange failed): confirm `.env` has a valid `OPENAI_API_KEY` and the proxy is running at <http(s)://localhost:8787>.
- Start does nothing or "Failed to fetch": the UI now checks `/health` before mic access. Ensure the realtime proxy is up (you should see `{"status":"ok"}` at `/health`). The launch scripts start both Streamlit and the proxy.
- CORS errors: the proxy is configured permissively for localhost in dev and exposes `OPTIONS` on `/sdp` and `/tool`.
- DuckDuckGo returns 202 (empty): for time queries, the proxy falls back to worldtimeapi.org and returns a time card.

### .env Loading

Both the Streamlit app and the realtime proxy load environment variables from the root `.env` using `python-dotenv`. You do not need to copy `.env` into `app/`.

### Where exports are stored

Exports are saved under `scratchpad/saved` relative to the project root. Update the path in `app/realtime_proxy.py` if you want a different location.
- No audio output: check system output device and browser autoplay policy; speak a word to ‚Äúunlock‚Äù audio. Try clicking Start again.
- Windows HTTPS: ensure `openssl.exe` is on PATH (e.g., via Git for Windows or OpenSSL install). Otherwise use the HTTP launcher.

## License

MIT

![AlitaOS loading animation](images/os1.gif)

## What‚Äôs Included

AlitaOS focuses on core functionality with a streamlined set of capabilities:

- Voice conversation via OpenAI Realtime (WebRTC)
- Image generation using OpenAI `gpt-image-1` (supports prompt, size, style)
- Web search via `/tool` endpoint with Tavily (if `TAVILY_API_KEY` present) or DuckDuckGo fallback

## Quick Start

### üöÄ Easy Launch (Recommended)

1. **Clone and Setup**
   ```bash
   git clone <repository-url>
   cd alitaOS-main
   ```

2. **Create Environment File**
   Create a `.env` file in the root directory:
   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   # Optional, enables Tavily for richer web results
   # TAVILY_API_KEY=your_tavily_api_key_here
   ```

3. **Install Dependencies**
   
   - macOS/Linux: `bash ./install_mac_linux.sh`
   - Windows: `install_windows.bat`

4. **Launch AlitaOS (Streamlit)**
   
   - macOS/Linux: `bash ./launch_streamlit.sh`
   - Windows: `launch_streamlit.bat`

5. **Test Functionality** (Optional)
   
   ```bash
   ./run_tests.sh
   ```

### üì± Access AlitaOS

- Streamlit app: <http://localhost:8501>

### üéôÔ∏è Voice Feature Notes

- Grant microphone permissions when prompted by your browser.
- Chrome/Edge have best compatibility for audio capture in Streamlit.
- If transcription fails, ensure your `OPENAI_API_KEY` is set and that your audio input device is working.

 
## Setup and Running

You can run AlitaOS using the provided install and launch scripts. Ensure your `.env` contains `OPENAI_API_KEY`.

### Option: Manual Setup

1. Create and activate a venv named `alitaOS` and install requirements:
   ```sh
   python3 -m venv alitaOS
   source alitaOS/bin/activate  # Windows: alitaOS\Scripts\activate
   pip install -r requirements.txt
   ```

2. Create `.env` with your key:
   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   ```

3. Launch Streamlit app:
   ```sh
   bash ./launch_streamlit.sh
   ```

### Option 2: Using Docker Compose

1. **Environment Variables**
   
   - Create a `.env` file in the root directory by copying `.env.example` and updating it with your own keys.

2. **Build and Run with Docker Compose**
   
   - Make sure Docker and Docker Compose are installed.
   - Run the following command:
     
     ```sh
     docker-compose up -d
     ```

## Tools and Features

Core tools in the Live Assistant:

- Realtime voice (OpenAI Realtime WebRTC)
- Image generation (OpenAI gpt-image-1)
- Web search (Tavily or DuckDuckGo fallback)
- File saving (`file.save`) for assistant replies and web results
